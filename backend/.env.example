# .env.example
# Copy this to .env and customize as needed
# Command: cp .env.example .env

# ============ MODEL CONFIGURATION ============
# Base model from Hugging Face (change this to switch models)
# Options: "gpt2", "distilgpt2", "meta-llama/Llama-3.1-8B-Instruct"
BASE_MODEL_NAME=gpt2

# Embedding model for ChromaDB RAG
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# ============ TRAINING CONFIGURATION ============
TRAINING_EPOCHS=10
BATCH_SIZE=2
LEARNING_RATE=0.0002
MAX_LENGTH=1024
FP16_TRAINING=true

# ============ LoRA HYPERPARAMETERS ============
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.05

# ============ CHROMADB CONFIGURATION ============
CHUNK_SIZE=400
CHUNK_OVERLAP=50
TOP_K_RETRIEVAL=3

# ============ STORAGE PATHS ============
# All paths are relative to project root
CHROMADB_PATH=./storage/chromadb
LORA_ADAPTERS_PATH=./storage/lora_adapters
TRAINING_METADATA_PATH=./storage/training_metadata
LOGS_PATH=./storage/logs
UPLOADED_PDFS_PATH=./storage/uploaded_pdfs

# ============ API CONFIGURATION ============
API_TITLE=NCERT Exam Evaluator API
API_VERSION=1.0.0
API_HOST=0.0.0.0
API_PORT=8001

# ============ VALIDATION LIMITS ============
MAX_PDF_SIZE_MB=50
MIN_TRAINING_EXAMPLES=5
MAX_TRAINING_EXAMPLES=500

# ============ PERFORMANCE SETTINGS ============
INFERENCE_TIMEOUT_SECONDS=30
MAX_GENERATION_LENGTH=300

# ============ LOGGING CONFIGURATION ============
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
LOG_ROTATION_DAYS=30
LOG_MAX_SIZE_MB=100